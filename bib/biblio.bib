@article{Wei16optimizing,
	author = {Xu, Wei  and Napoles, Courtney  and Pavlick, Ellie  and Chen, Quanze  and Callison-Burch, Chris },
	title = {Optimizing Statistical Machine Translation for Text Simplification},
	journal = {Transactions of the Association for Computational Linguistics},
	volume = {4},
	year = {2016},
	keywords = {Methods in ATS},
	abstract = {Most recent sentence simplification systems use basic machine translation models to learn lexical and syntactic paraphrases from a manually simplified parallel corpus. These methods are limited by the quality and quantity of manually simplified corpora, which are expensive to build. In this paper, we conduct an in-depth adaptation of statistical machine translation to perform text simplification, taking advantage of large-scale paraphrases learned from bilingual texts and a small amount of manual simplifications with multiple references. Our work is the first to design automatic metrics that are effective for tuning and evaluating simplification systems, which will facilitate iterative development for this task.},
	issn = {2307-387X},
	url = {https://www.transacl.org/ojs/index.php/tacl/article/view/741},
	pages = {401--415}
}

@article{Koponen21bridge,
title = "User perspectives on developing technology-assisted access services in public broadcasting",
abstract = "The growing demand for accessible media content in the Creative Industries and increased pressure to produce more content at lower costs has led the industry to look for technological support for creating and managing audiovisual content. In order to design technology-assisted solutions and services that are truly accessible, it is crucial to center the knowledge and experience of the intended users - both the consumers and the professionals involved in producing the content and services. This article explores potential technological solutions for audiovisual media access services in the context of public service television broadcasting. We introduce an ongoing research project taking a user-centered approach, and present work carried out on automatic and semi-automatic methods involving intralingual and interlingual subtitling, and description of visual content. Through experiments and interviews, we examine how different potential user groups respond to technological solutions at differing levels of maturity. We discuss conceptualizations of quality, trust, and accessibility emerging in the interviews, and chart the differences and similarities between different stakeholders. The article demonstrates how the diverse user perspectives can inform research and development, and enhance our understanding of the role of technology in promoting media accessibility.",
author = "Maarit Koponen and Tiina Tuominen and Maija Hirvonen and Kaisa Vitikainen and Liisa Tiittula",
year = "2021",
month = jan,
language = "English",
volume = "1",
pages = "47--67",
journal = "Bridge: Trends and Traditions in Translation and Interpreting Studies",
issn = "2729-8183",
publisher = "Department of Translation Studies, Faculty of Arts Constantine the Philosopher University in Nitra",
number = "2",

}

@article{Martinez-Hinarejos15unsegmented,
author = {Mart\'{i}nez-Hinarejos, Carlos D. and Bened\'{i}, Jos\'{e}-Miguel and Tamarit, Vicent},
title = {Unsegmented Dialogue Act Annotation and Decoding with N-Gram Transducers},
year = {2015},
issue_date = {January 2015},
publisher = {IEEE Press},
volume = {23},
number = {1},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2014.2377595},
doi = {10.1109/TASLP.2014.2377595},
abstract = {Most studies on dialogue corpora, as well as most dialogue systems, employ dialogue acts as the basic units for interpreting discourse structure, user input and system actions. The definition of the discourse structure and the dialogue strategy consequently require the tagging of dialogue corpora in terms of dialogue acts. The tagging problem presents two basic variants: a batch variant (annotation of whole dialogues, in order to define dialogue strategy or study discourse structure) and an online variant (decoding of the dialogue act sequence of a given turn, in order to interpret user intentions). In the two variants is unusual having the segmentation of each turn into the dialogue meaningful units (segments) to which a dialogue act is assigned. In this paper we present the use of the N-Gram Transducer technique for tagging dialogues, without needing to provide a prior segmentation, in these two different variants (dialogue annotation and turn decoding). Experiments were performed in two corpora of different nature and results show that N-Gram Transducer models are suitable for these tasks and provide good performance.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jan,
pages = {198–211},
numpages = {14},
keywords = {n-gram transducer, dialogue annotation, spoken dialogue systems}
}
@inproceedings{Fournier12segmentation,
    title = "Segmentation Similarity and Agreement",
    author = "Fournier, Chris  and
      Inkpen, Diana",
    booktitle = "Proceedings of the 2012 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2012",
    address = "Montr{\'e}al, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N12-1016",
    pages = "152--161",
}

@inproceedings{Fournier13evaluating,
    title = "Evaluating Text Segmentation using Boundary Edit Distance",
    author = "Fournier, Chris",
    booktitle = "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P13-1167",
    pages = "1702--1712",
}

@inproceedings{Snover06study,
	Address = {Boston, Massachusetts, USA},
	Author = {Snover, Matthew and Dorr, Bonnie and Schwartz, Richard and Micciulla, Linnea and Makhoul, John},
	Booktitle = {Proceedings of the seventh conference of the Association for Machine Translation in the America (AMTA)},
	Pages = {223--231},
	Title = {{A Study of Translation Edit Rate with Targeted Human Annotation}},
	Url = {http://www.mt-archive.info/AMTA-2006-Snover.pdf},
	Year = {2006},
}

@inproceedings{Banerjee05meteor,
	Address = {Ann Arbor, Michigan},
	Author = {Banerjee, Satanjeev and Lavie, Alon},
	Booktitle = {Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation},
	Pages = {65--72},
	Title = {{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments},
	Url = {http://www.aclweb.org/anthology/W/W05/W05-0909},
	Year = {2005},
}

@inproceedings{Papineni02bleu,
	Address = {Stroudsburg, PA, USA},
	Author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
	Booktitle = {Proceedings of the 40th Annual Meeting on Association for Computational Linguistics},
	Doi = {http://dx.doi.org/10.3115/1073083.1073135},
	Location = {Philadelphia, Pennsylvania},
	Numpages = {8},
	Pages = {311--318},
	Publisher = {Association for Computational Linguistics},
	Title = {{BLEU}: a method for automatic evaluation of machine translation},
	Url = {http://dx.doi.org/10.3115/1073083.1073135},
	Year = {2002},
	}

@inproceedings{Karakanta20is42,
    title = "Is 42 the Answer to Everything in Subtitling-oriented Speech Translation?",
    author = "Karakanta, Alina and Negri, Matteo and Turchi, Marco",
    booktitle = "Proceedings of the 17th International Conference on Spoken Language Translation",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.iwslt-1.26",
    doi = "10.18653/v1/2020.iwslt-1.26",
    pages = "209--219",
    abstract = "Subtitling is becoming increasingly important for disseminating information, given the enormous amounts of audiovisual content becoming available daily. Although Neural Machine Translation (NMT) can speed up the process of translating audiovisual content, large manual effort is still required for transcribing the source language, and for spotting and segmenting the text into proper subtitles. Creating proper subtitles in terms of timing and segmentation highly depends on information present in the audio (utterance duration, natural pauses). In this work, we explore two methods for applying Speech Translation (ST) to subtitling, a) a direct end-to-end and b) a classical cascade approach. We discuss the benefit of having access to the source language speech for improving the conformity of the generated subtitles to the spatial and temporal subtitling constraints and show that length is not the answer to everything in the case of subtitling-oriented ST.",
}

@inproceedings{Volk10machine,
  title={Machine translation of TV subtitles for large scale production},
  author={Volk, Martin and Sennrich, Rico and Hardmeier, Christian and Tidstr{\"o}m, Frida},
  year={2010},
  booktitle={Proceedings of JEC 2010},
  pages = {53-–62}, 
  publisher={Association for Machine Translation in the Americas}
}

@inproceedings{Matusov19customizing,
    title = "Customizing Neural Machine Translation for Subtitling",
    author = "Matusov, Evgeny and Wilken, Patrick and Georgakopoulou, Yota",
    booktitle = "Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)",
    month = aug,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-5209",
    doi = "10.18653/v1/W19-5209",
    pages = "82--93",
    abstract = "In this work, we customized a neural machine translation system for translation of subtitles in the domain of entertainment. The neural translation model was adapted to the subtitling content and style and extended by a simple, yet effective technique for utilizing inter-sentence context for short sentences such as dialog turns. The main contribution of the paper is a novel subtitle segmentation algorithm that predicts the end of a subtitle line given the previous word-level context using a recurrent neural network learned from human segmentation decisions. This model is combined with subtitle length and duration constraints established in the subtitling industry. We conducted a thorough human evaluation with two post-editors (English-to-Spanish translation of a documentary and a sitcom). It showed a notable productivity increase of up to 37{\%} as compared to translating from scratch and significant reductions in human translation edit rate in comparison with the post-editing of the baseline non-adapted system without a learned segmentation model.",
}

@article{Alvarez17improving,
title = {Improving the automatic segmentation of subtitles through conditional random field},
journal = {Speech Communication},
volume = {88},
pages = {83-95},
year = {2017},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2017.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0167639316300127},
author = {Aitor Álvarez and Carlos-D. Martínez-Hinarejos and Haritz Arzelus and Marina Balenciaga and Arantza {del Pozo}},
keywords = {Automatic subtitling, Subtitle segmentation, Pattern recognition, Machine learning},
abstract = {Automatic segmentation of subtitles is a novel research field which has not been studied extensively to date. However, quality automatic subtitling is a real need for broadcasters which seek for automatic solutions given the demanding European audiovisual legislation. In this article, a method based on Conditional Random Field is presented to deal with the automatic subtitling segmentation. This is a continuation of a previous work in the field, which proposed a method based on Support Vector Machine classifier to generate possible candidates for breaks. For this study, two corpora in Basque and Spanish were used for experiments, and the performance of the current method was tested and compared with the previous solution and two rule-based systems through several evaluation metrics. Finally, an experiment with human evaluators was carried out with the aim of measuring the productivity gain in post-editing automatic subtitles generated with the new method presented.}
}

@inproceedings{alvarez-et-al-2016,
title={Impact of automatic segmentation on the quality,productivity and self-reported post-editing effort of intralingual subtitles},
author={Aitor Álvareze and Marina Balenciaga and Arantza del Pozo and Haritz Arzelus and Anna Matamala and Carlos-D. Mart́ınez-Hinarejos},
year={2016},
booktitle={Proceedings of LREC}
}

@Article{Beeferman99statistical,
  author =       {Doug Beeferman and Adam Berger and John Lafferty},
  title =        {Statistical Models for Text Segmentation},
  journal =      {Machine Learning},
  pages =        {177--210},
  volume =       34,
  number =       {1-3},
  year =         1999
}

@inproceedings{Bull20automatic,
  title={Automatic segmentation of sign language into subtitle-units},
  author={Bull, Hannah and Gouiff{\`e}s, Mich{\`e}le and Braffort, Annelies},
  booktitle={European Conference on Computer Vision},
  pages={186--198},
  year={2020},
  organization={Springer}
}

@article{Goldwater09bayesian,
	Author = {Sharon Goldwater and Thomas L. Griffiths and Mark Johnson},
	Journal = {Cognition},
	Number = {1},
	Pages = {21--54},
	Title = {A {Bayesian} framework for word segmentation: Exploring the effects of context},
	Volume = {112},
	Year = {2009}
}

@Article{Hearst97textiling,
  author = 	 {Marti Hearst},
  title = 	 {{TextTiling}: Segmenting texts into multi-paragraph subtopic passages},
  journal = 	 {Computational Linguisitics},
  year = 	 1997,
  volume =	 23,
  number =	 1,
  pages =	 {33--64}
}

@inproceedings{Kurzhals17close,
author = {Kurzhals, Kuno and Cetinkaya, Emine and Hu, Yongtao and Wang, Wenping and Weiskopf, Daniel},
title = {Close to the Action: Eye-Tracking Evaluation of Speaker-Following Subtitles},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025772},
doi = {10.1145/3025453.3025772},
abstract = {The incorporation of subtitles in multimedia content plays an important role in communicating spoken content. For example, subtitles in the respective language are often preferred to expensive audio translation of foreign movies. The traditional representation of subtitles displays text centered at the bottom of the screen. This layout can lead to large distances between text and relevant image content, causing eye strain and even that we miss visual content. As a recent alternative, the technique of speaker-following subtitles places subtitle text in speech bubbles close to the current speaker. We conducted a controlled eye-tracking laboratory study (n = 40) to compare the regular approach (center-bottom subtitles) with content-sensitive, speaker-following subtitles. We compared different dialog-heavy video clips with the two layouts. Our results show that speaker-following subtitles lead to higher fixation counts on relevant image regions and reduce saccade length, which is an important factor for eye strain.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6559–6568},
numpages = {10},
keywords = {subtitle layout, eye tracking, video},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@misc{NIST03evalplan,
author = {The NIST Evaluation group},
year = {2003},
title = {The Rich Transcription Fall 2003 (RT-03F) Evaluation Plan},
url = "https://catalog.ldc.upenn.edu/docs/LDC2004T12/rt03-fall-eval-plan-v9.pdf"
}

@article{Perego13cognitive,
author = {Elisa Perego and Fabio Del Missier and  Marco Porta and Mauro Mosconi },
title = {The Cognitive Effectiveness of Subtitle Processing},
journal = {Media Psychology},
volume = {13},
number = {3},
pages = {243-272},
year  = {2010},
publisher = {Routledge},
doi = {10.1080/15213269.2010.502873},
URL = {https://doi.org/10.1080/15213269.2010.502873},
eprint = {https://doi.org/10.1080/15213269.2010.502873},    
}

@article{Pevzner02critique,
    title = "A Critique and Improvement of an Evaluation Metric for Text Segmentation",
    author = "Pevzner, Lev  and
      Hearst, Marti A.",
    journal = "Computational Linguistics",
    volume = "28",
    number = "1",
    year = "2002",
    url = "https://www.aclweb.org/anthology/J02-1002",
    doi = "10.1162/089120102317341756",
    pages = "19--36",
}

@inproceedings{Scaiano10automatic,
  title={Automatic text segmentation for movie subtitles},
  author={Scaiano, Martin and Inkpen, Diana and Laganiere, Robert and Reinhartz, Adele},
  booktitle={Canadian Conference on Artificial Intelligence},
  pages={295--298},
  year={2010},
  organization={Springer}
}

@inproceedings{liu-etal-2020-adapting,
    title = "Adapting End-to-End Speech Recognition for Readable Subtitles",
    author = "Liu, Danni  and
      Niehues, Jan  and
      Spanakis, Gerasimos",
    booktitle = "Proceedings of the 17th International Conference on Spoken Language Translation",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.iwslt-1.30",
    doi = "10.18653/v1/2020.iwslt-1.30",
    pages = "247--256"
}

@misc{niehues-2020,
  author ={Jan  Niehues},
  year = {2020},
 title = {Machine  translation  with  un-supervised length-constraints},
 eprint={2004.03176},
 archivePrefix={arXiv},
 primaryClass={cs.CL}
}

@inproceedings{lakew-et-al-2019,
author = {Surafel  Melaku  Lakew and Mattia  Di  Gangi and  Marcello Federico},
year = {2019},
title = {Controlling the output length of  neural  machine  translation}, booktitle = {Proceedings of IWSLT’2019}
}
@inproceedings{Creutz02unsupervised,
	Author = {Mathias Creutz and Krista Lagus},
	Booktitle = {Proceedings of the ACL-02 Workshop on Morphological and Phonological Learning},
	Doi = {10.3115/1118647.1118650},
	Month = {July},
	Pages = {21--30},
	Publisher = {Association for Computational Linguistics},
	Title = {Unsupervised Discovery of Morphemes},
	Url = {http://www.aclweb.org/anthology/W02-0603},
	Year = {2002},
	Bdsk-Url-1 = {http://www.aclweb.org/anthology/W02-0603},
	Bdsk-Url-2 = {http://dx.doi.org/10.3115/1118647.1118650}}
